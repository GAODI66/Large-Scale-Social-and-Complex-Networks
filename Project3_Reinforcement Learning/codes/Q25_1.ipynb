{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q25_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cvxopt import matrix, solvers\n",
    "\n",
    "\n",
    "# Define Probability Function P_{SS'}^{a}\n",
    "def probability(currS, nextS, move, prob):\n",
    "    left = currS + actions[0]\n",
    "    up = currS + actions[1]\n",
    "    right = currS + actions[2]\n",
    "    down = currS + actions[3]\n",
    "    if nextS == left:\n",
    "        if move == 0:\n",
    "            return 1-prob+prob/4\n",
    "        else:\n",
    "            return prob/4\n",
    "    elif nextS == up:\n",
    "        if move == 1:\n",
    "            return 1-prob+prob/4\n",
    "        else:\n",
    "            return prob/4\n",
    "    elif nextS == right:\n",
    "        if move == 2:\n",
    "            return 1-prob+prob/4\n",
    "        else:\n",
    "            return prob/4\n",
    "    elif nextS == down:\n",
    "        if move == 3:\n",
    "            return 1-prob+prob/4\n",
    "        else:\n",
    "            return prob/4\n",
    "    elif nextS == currS:\n",
    "        record = 0\n",
    "        if left < 0:\n",
    "            if move == 0:\n",
    "                record += (1-prob+prob/4)\n",
    "            else:\n",
    "                record += prob/4\n",
    "        if right > 99:\n",
    "            if move == 2:\n",
    "                record += (1-prob+prob/4)\n",
    "            else:\n",
    "                record += prob/4\n",
    "        if up % 10 == 9:\n",
    "            if move == 1:\n",
    "                record += (1-prob+prob/4)\n",
    "            else:\n",
    "                record += prob/4\n",
    "        if down % 10 == 0:\n",
    "            if move == 3:\n",
    "                record += (1-prob+prob/4)\n",
    "            else:\n",
    "                record += prob/4\n",
    "        return record\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# Procedure Value Iteration\n",
    "def compute(currS, move, prob, gamma, reward, values):\n",
    "    left = currS + actions[0]\n",
    "    right = currS + actions[2]\n",
    "    up = currS + actions[1]\n",
    "    down = currS + actions[3]\n",
    "    neighbours = [left, right, up, down, currS]\n",
    "    result = 0\n",
    "    for neigh in neighbours:\n",
    "        if neigh < 0 or neigh > 99 or (currS % 10 == 0 and neigh % 10 == 9) or (currS % 10 == 9 and neigh % 10 == 0):\n",
    "            continue\n",
    "        result += probability(currS, neigh, move, prob) * (reward[neigh] + gamma * values[neigh])\n",
    "    return result\n",
    "\n",
    "\n",
    "def optimal_state_val(values, w, gamma, reward, threshold):\n",
    "    # 1) Initialization\n",
    "    for state in range(100):\n",
    "        values[state] = 0\n",
    "    # 2) Estimation\n",
    "    delta = float('inf')\n",
    "    while delta > threshold:\n",
    "        delta = 0\n",
    "        temp = values[:]\n",
    "        for state in range(100):\n",
    "            v = values[state]\n",
    "            values[state] = max(compute(state, 0, w, gamma, reward, temp),\n",
    "                                compute(state, 1, w, gamma, reward, temp),\n",
    "                                compute(state, 2, w, gamma, reward, temp),\n",
    "                                compute(state, 3, w, gamma, reward, temp))\n",
    "            delta = max(delta, abs(v - values[state]))\n",
    "    return values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get transition probabilities where all actions are same\n",
    "def raw_matrix(length, w, direction):\n",
    "    s = length * length\n",
    "    res = np.zeros(s * s).reshape(s, s)\n",
    "    main_possibility = 1 - w\n",
    "    random_possibility = w / 4\n",
    "    for row in range(s):\n",
    "        nexts = next_states(length, row)\n",
    "        if direction == \"up\":\n",
    "            res[row][nexts[0]] = main_possibility\n",
    "        elif direction == \"down\":\n",
    "            res[row][nexts[1]] = main_possibility\n",
    "        elif direction == \"left\":\n",
    "            res[row][nexts[2]] = main_possibility\n",
    "        elif direction == \"right\":\n",
    "            res[row][nexts[3]] = main_possibility\n",
    "        for col in nexts:\n",
    "            res[row][col] += random_possibility\n",
    "    return res\n",
    "        \n",
    "def next_states(length, cur_state):\n",
    "    x = cur_state % length\n",
    "    y = cur_state // length\n",
    "    up = cur_state - 1\n",
    "    down = cur_state + 1\n",
    "    left = cur_state - length\n",
    "    right = cur_state + length\n",
    "    if x == 0:\n",
    "        up = cur_state\n",
    "    if x == length - 1:\n",
    "        down = cur_state\n",
    "    if y == 0:\n",
    "        left = cur_state\n",
    "    if y == length - 1:\n",
    "        right = cur_state\n",
    "    return np.array([up, down, left, right])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get c, D, b arguments for solving LP later\n",
    "def get_c_D_b(exp_action, P_actions, lam, rmax):\n",
    "    # create P_exp(P_a1), P_ag1(P_a), P_ag2(P_a), P_ag3(P_a)\n",
    "    P_exp = []\n",
    "    P_ags = []\n",
    "    P_ags.append([])\n",
    "    P_ags.append([])\n",
    "    P_ags.append([])\n",
    "    for state in range(100):\n",
    "        exp_act = exp_action[state]\n",
    "        agent = 0\n",
    "        for action in range(4):\n",
    "            if action == exp_act:\n",
    "                P_exp.append(P_actions[action][state])\n",
    "            else:\n",
    "                P_ags[agent].append(P_actions[action][state])\n",
    "                agent += 1\n",
    "\n",
    "    I = np.eye(100)\n",
    "    zero = np.zeros(100 * 100).reshape(100, 100)\n",
    "    D = np.concatenate((zero, zero, zero, zero))\n",
    "    D = np.concatenate((D, np.concatenate((-I, -I, zero, zero)), \n",
    "                        np.concatenate((I, -I, I, -I))), 1)\n",
    " \n",
    "    for Pa in P_ags:\n",
    "        # (Pa-Pa1)(I-ga*Pa1)^(-1)\n",
    "        temp = np.dot((np.array(Pa) - np.array(P_exp)), \n",
    "                      np.linalg.inv(np.eye(100) - 0.8 * np.array(P_exp)))\n",
    "        temp_row1 = np.concatenate((I, zero, temp), 1)\n",
    "        temp_row2 = np.concatenate((zero, zero, temp), 1)\n",
    "        temp = np.concatenate((temp_row1, temp_row2))\n",
    "        D = np.concatenate((temp, D))\n",
    "        \n",
    "    c1 = np.array([1. for _ in range(100)])\n",
    "    c2 = np.array([-lam for _ in range(100)])\n",
    "    c3 = np.array([0.0 for _ in range(100)])\n",
    "    c = np.concatenate((c1, c2, c3), axis=0)\n",
    "    c = -c\n",
    "    b1 = np.array([0.0 for _ in range(800)])\n",
    "    b2 = np.array([rmax for _ in range(200)])\n",
    "    b = np.concatenate((b1, b2), axis=0)\n",
    "    return c, D, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve a LP to get reward\n",
    "def get_reward(c, D, b):\n",
    "    A = matrix(D)\n",
    "    b = matrix(b)\n",
    "    c = matrix(c)\n",
    "    solvers.options['show_progress'] = False\n",
    "    sol=solvers.lp(c,A,b)\n",
    "    return sol['x'][-100:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep(exp_action, rmax):\n",
    "    acc_list = []\n",
    "    lam_list = []\n",
    "    lam = 0\n",
    "    for i in range(501):\n",
    "        c, D, b = get_c_D_b(exp_action, P_acts, lam, rmax)\n",
    "        reward = np.array(get_reward(c, D, b))\n",
    "        value = optimal_state_val(values, w, gamma, reward, thres)\n",
    "        # OA\n",
    "        agent_action = [0 for _ in range(100)]\n",
    "        for state in range(100):\n",
    "            agent_action[state] = np.argmax([compute(state, 0, w, gamma, reward, value),\n",
    "                                             compute(state, 1, w, gamma, reward, value),\n",
    "                                             compute(state, 2, w, gamma, reward, value),\n",
    "                                             compute(state, 3, w, gamma, reward, value)])\n",
    "        count = 0\n",
    "        for j, k in zip(exp_action, agent_action):\n",
    "            if j == k:\n",
    "                count += 1\n",
    "        acc = count / len(agent_action)\n",
    "        \n",
    "        print(\"lambda: \" + str(lam) + \"  acc: \" + str(acc))\n",
    "        acc_list.append(acc)\n",
    "        lam_list.append(lam)\n",
    "        lam += 0.01\n",
    "    return lam_list, acc_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Environment of the Agent\n",
    "values = [0 for _ in range(100)]\n",
    "thres = 0.01\n",
    "actions = [-10, -1, 10, 1] # left, up, right, down\n",
    "w = 0.1\n",
    "gamma = 0.8\n",
    "\n",
    "P_acts = []\n",
    "P_acts.append(raw_matrix(10, 0.1, \"left\"))\n",
    "P_acts.append(raw_matrix(10, 0.1, \"up\"))\n",
    "P_acts.append(raw_matrix(10, 0.1, \"right\"))\n",
    "P_acts.append(raw_matrix(10, 0.1, \"down\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda: 0  acc: 0.82\n",
      "lambda: 0.01  acc: 0.8\n",
      "lambda: 0.02  acc: 0.78\n",
      "lambda: 0.03  acc: 0.79\n",
      "lambda: 0.04  acc: 0.78\n",
      "lambda: 0.05  acc: 0.78\n",
      "lambda: 0.060000000000000005  acc: 0.8\n",
      "lambda: 0.07  acc: 0.84\n",
      "lambda: 0.08  acc: 0.83\n",
      "lambda: 0.09  acc: 0.83\n",
      "lambda: 0.09999999999999999  acc: 0.84\n",
      "lambda: 0.10999999999999999  acc: 0.83\n",
      "lambda: 0.11999999999999998  acc: 0.81\n",
      "lambda: 0.12999999999999998  acc: 0.81\n",
      "lambda: 0.13999999999999999  acc: 0.79\n",
      "lambda: 0.15  acc: 0.79\n",
      "lambda: 0.16  acc: 0.81\n",
      "lambda: 0.17  acc: 0.81\n",
      "lambda: 0.18000000000000002  acc: 0.82\n",
      "lambda: 0.19000000000000003  acc: 0.82\n",
      "lambda: 0.20000000000000004  acc: 0.83\n",
      "lambda: 0.21000000000000005  acc: 0.82\n",
      "lambda: 0.22000000000000006  acc: 0.83\n",
      "lambda: 0.23000000000000007  acc: 0.83\n",
      "lambda: 0.24000000000000007  acc: 0.83\n",
      "lambda: 0.25000000000000006  acc: 0.89\n",
      "lambda: 0.26000000000000006  acc: 0.89\n",
      "lambda: 0.2700000000000001  acc: 0.88\n",
      "lambda: 0.2800000000000001  acc: 0.88\n",
      "lambda: 0.2900000000000001  acc: 0.88\n",
      "lambda: 0.3000000000000001  acc: 0.88\n",
      "lambda: 0.3100000000000001  acc: 0.88\n",
      "lambda: 0.3200000000000001  acc: 0.89\n",
      "lambda: 0.3300000000000001  acc: 0.88\n",
      "lambda: 0.34000000000000014  acc: 0.88\n",
      "lambda: 0.35000000000000014  acc: 0.88\n",
      "lambda: 0.36000000000000015  acc: 0.89\n",
      "lambda: 0.37000000000000016  acc: 0.89\n",
      "lambda: 0.38000000000000017  acc: 0.9\n",
      "lambda: 0.3900000000000002  acc: 0.9\n",
      "lambda: 0.4000000000000002  acc: 0.92\n",
      "lambda: 0.4100000000000002  acc: 0.92\n",
      "lambda: 0.4200000000000002  acc: 0.92\n",
      "lambda: 0.4300000000000002  acc: 0.91\n",
      "lambda: 0.4400000000000002  acc: 0.93\n",
      "lambda: 0.45000000000000023  acc: 0.91\n",
      "lambda: 0.46000000000000024  acc: 0.91\n",
      "lambda: 0.47000000000000025  acc: 0.91\n",
      "lambda: 0.48000000000000026  acc: 0.92\n",
      "lambda: 0.49000000000000027  acc: 0.92\n",
      "lambda: 0.5000000000000002  acc: 0.93\n",
      "lambda: 0.5100000000000002  acc: 0.93\n",
      "lambda: 0.5200000000000002  acc: 0.93\n",
      "lambda: 0.5300000000000002  acc: 0.94\n",
      "lambda: 0.5400000000000003  acc: 0.92\n",
      "lambda: 0.5500000000000003  acc: 0.93\n",
      "lambda: 0.5600000000000003  acc: 0.93\n",
      "lambda: 0.5700000000000003  acc: 0.94\n",
      "lambda: 0.5800000000000003  acc: 0.93\n",
      "lambda: 0.5900000000000003  acc: 0.93\n",
      "lambda: 0.6000000000000003  acc: 0.93\n",
      "lambda: 0.6100000000000003  acc: 0.94\n",
      "lambda: 0.6200000000000003  acc: 0.93\n",
      "lambda: 0.6300000000000003  acc: 0.93\n",
      "lambda: 0.6400000000000003  acc: 0.93\n",
      "lambda: 0.6500000000000004  acc: 0.93\n",
      "lambda: 0.6600000000000004  acc: 0.93\n",
      "lambda: 0.6700000000000004  acc: 0.94\n",
      "lambda: 0.6800000000000004  acc: 0.93\n",
      "lambda: 0.6900000000000004  acc: 0.93\n",
      "lambda: 0.7000000000000004  acc: 0.92\n",
      "lambda: 0.7100000000000004  acc: 0.92\n",
      "lambda: 0.7200000000000004  acc: 0.92\n",
      "lambda: 0.7300000000000004  acc: 0.93\n",
      "lambda: 0.7400000000000004  acc: 0.93\n",
      "lambda: 0.7500000000000004  acc: 0.92\n",
      "lambda: 0.7600000000000005  acc: 0.92\n",
      "lambda: 0.7700000000000005  acc: 0.95\n",
      "lambda: 0.7800000000000005  acc: 0.93\n",
      "lambda: 0.7900000000000005  acc: 0.93\n",
      "lambda: 0.8000000000000005  acc: 0.92\n",
      "lambda: 0.8100000000000005  acc: 0.92\n",
      "lambda: 0.8200000000000005  acc: 0.92\n",
      "lambda: 0.8300000000000005  acc: 0.93\n",
      "lambda: 0.8400000000000005  acc: 0.92\n",
      "lambda: 0.8500000000000005  acc: 0.93\n",
      "lambda: 0.8600000000000005  acc: 0.94\n",
      "lambda: 0.8700000000000006  acc: 0.91\n",
      "lambda: 0.8800000000000006  acc: 0.91\n",
      "lambda: 0.8900000000000006  acc: 0.92\n",
      "lambda: 0.9000000000000006  acc: 0.91\n",
      "lambda: 0.9100000000000006  acc: 0.93\n",
      "lambda: 0.9200000000000006  acc: 0.95\n",
      "lambda: 0.9300000000000006  acc: 0.92\n",
      "lambda: 0.9400000000000006  acc: 0.94\n",
      "lambda: 0.9500000000000006  acc: 0.94\n",
      "lambda: 0.9600000000000006  acc: 0.92\n",
      "lambda: 0.9700000000000006  acc: 0.92\n",
      "lambda: 0.9800000000000006  acc: 0.92\n",
      "lambda: 0.9900000000000007  acc: 0.92\n",
      "lambda: 1.0000000000000007  acc: 0.93\n",
      "lambda: 1.0100000000000007  acc: 0.94\n",
      "lambda: 1.0200000000000007  acc: 0.93\n",
      "lambda: 1.0300000000000007  acc: 0.94\n",
      "lambda: 1.0400000000000007  acc: 0.93\n",
      "lambda: 1.0500000000000007  acc: 0.93\n",
      "lambda: 1.0600000000000007  acc: 0.93\n",
      "lambda: 1.0700000000000007  acc: 0.93\n",
      "lambda: 1.0800000000000007  acc: 0.93\n",
      "lambda: 1.0900000000000007  acc: 0.93\n",
      "lambda: 1.1000000000000008  acc: 0.94\n",
      "lambda: 1.1100000000000008  acc: 0.94\n",
      "lambda: 1.1200000000000008  acc: 0.93\n",
      "lambda: 1.1300000000000008  acc: 0.94\n",
      "lambda: 1.1400000000000008  acc: 0.94\n",
      "lambda: 1.1500000000000008  acc: 0.94\n",
      "lambda: 1.1600000000000008  acc: 0.94\n",
      "lambda: 1.1700000000000008  acc: 0.94\n",
      "lambda: 1.1800000000000008  acc: 0.93\n",
      "lambda: 1.1900000000000008  acc: 0.94\n",
      "lambda: 1.2000000000000008  acc: 0.94\n",
      "lambda: 1.2100000000000009  acc: 0.94\n",
      "lambda: 1.2200000000000009  acc: 0.94\n",
      "lambda: 1.2300000000000009  acc: 0.94\n",
      "lambda: 1.2400000000000009  acc: 0.94\n",
      "lambda: 1.2500000000000009  acc: 0.94\n",
      "lambda: 1.260000000000001  acc: 0.94\n",
      "lambda: 1.270000000000001  acc: 0.94\n",
      "lambda: 1.280000000000001  acc: 0.94\n",
      "lambda: 1.290000000000001  acc: 0.94\n",
      "lambda: 1.300000000000001  acc: 0.94\n",
      "lambda: 1.310000000000001  acc: 0.94\n",
      "lambda: 1.320000000000001  acc: 0.94\n",
      "lambda: 1.330000000000001  acc: 0.94\n",
      "lambda: 1.340000000000001  acc: 0.94\n",
      "lambda: 1.350000000000001  acc: 0.94\n",
      "lambda: 1.360000000000001  acc: 0.95\n",
      "lambda: 1.370000000000001  acc: 0.93\n",
      "lambda: 1.380000000000001  acc: 0.93\n",
      "lambda: 1.390000000000001  acc: 0.93\n",
      "lambda: 1.400000000000001  acc: 0.93\n",
      "lambda: 1.410000000000001  acc: 0.93\n",
      "lambda: 1.420000000000001  acc: 0.92\n",
      "lambda: 1.430000000000001  acc: 0.92\n",
      "lambda: 1.440000000000001  acc: 0.91\n",
      "lambda: 1.450000000000001  acc: 0.91\n",
      "lambda: 1.460000000000001  acc: 0.91\n",
      "lambda: 1.470000000000001  acc: 0.91\n",
      "lambda: 1.480000000000001  acc: 0.91\n",
      "lambda: 1.490000000000001  acc: 0.91\n",
      "lambda: 1.500000000000001  acc: 0.91\n",
      "lambda: 1.5100000000000011  acc: 0.91\n",
      "lambda: 1.5200000000000011  acc: 0.91\n",
      "lambda: 1.5300000000000011  acc: 0.91\n",
      "lambda: 1.5400000000000011  acc: 0.91\n",
      "lambda: 1.5500000000000012  acc: 0.91\n",
      "lambda: 1.5600000000000012  acc: 0.92\n",
      "lambda: 1.5700000000000012  acc: 0.92\n",
      "lambda: 1.5800000000000012  acc: 0.92\n",
      "lambda: 1.5900000000000012  acc: 0.92\n",
      "lambda: 1.6000000000000012  acc: 0.92\n",
      "lambda: 1.6100000000000012  acc: 0.92\n",
      "lambda: 1.6200000000000012  acc: 0.92\n",
      "lambda: 1.6300000000000012  acc: 0.92\n",
      "lambda: 1.6400000000000012  acc: 0.93\n",
      "lambda: 1.6500000000000012  acc: 0.92\n",
      "lambda: 1.6600000000000013  acc: 0.92\n",
      "lambda: 1.6700000000000013  acc: 0.92\n",
      "lambda: 1.6800000000000013  acc: 0.93\n",
      "lambda: 1.6900000000000013  acc: 0.93\n",
      "lambda: 1.7000000000000013  acc: 0.92\n",
      "lambda: 1.7100000000000013  acc: 0.93\n",
      "lambda: 1.7200000000000013  acc: 0.93\n",
      "lambda: 1.7300000000000013  acc: 0.93\n",
      "lambda: 1.7400000000000013  acc: 0.93\n",
      "lambda: 1.7500000000000013  acc: 0.93\n",
      "lambda: 1.7600000000000013  acc: 0.93\n",
      "lambda: 1.7700000000000014  acc: 0.93\n",
      "lambda: 1.7800000000000014  acc: 0.93\n",
      "lambda: 1.7900000000000014  acc: 0.93\n",
      "lambda: 1.8000000000000014  acc: 0.93\n",
      "lambda: 1.8100000000000014  acc: 0.93\n",
      "lambda: 1.8200000000000014  acc: 0.93\n",
      "lambda: 1.8300000000000014  acc: 0.92\n",
      "lambda: 1.8400000000000014  acc: 0.92\n",
      "lambda: 1.8500000000000014  acc: 0.92\n",
      "lambda: 1.8600000000000014  acc: 0.92\n",
      "lambda: 1.8700000000000014  acc: 0.92\n",
      "lambda: 1.8800000000000014  acc: 0.92\n",
      "lambda: 1.8900000000000015  acc: 0.92\n",
      "lambda: 1.9000000000000015  acc: 0.92\n",
      "lambda: 1.9100000000000015  acc: 0.92\n",
      "lambda: 1.9200000000000015  acc: 0.9\n",
      "lambda: 1.9300000000000015  acc: 0.9\n",
      "lambda: 1.9400000000000015  acc: 0.89\n",
      "lambda: 1.9500000000000015  acc: 0.89\n",
      "lambda: 1.9600000000000015  acc: 0.89\n",
      "lambda: 1.9700000000000015  acc: 0.89\n",
      "lambda: 1.9800000000000015  acc: 0.89\n",
      "lambda: 1.9900000000000015  acc: 0.89\n",
      "lambda: 2.0000000000000013  acc: 0.89\n",
      "lambda: 2.010000000000001  acc: 0.89\n",
      "lambda: 2.020000000000001  acc: 0.89\n",
      "lambda: 2.0300000000000007  acc: 0.89\n",
      "lambda: 2.0400000000000005  acc: 0.89\n",
      "lambda: 2.0500000000000003  acc: 0.89\n",
      "lambda: 2.06  acc: 0.89\n",
      "lambda: 2.07  acc: 0.89\n",
      "lambda: 2.0799999999999996  acc: 0.89\n",
      "lambda: 2.0899999999999994  acc: 0.89\n",
      "lambda: 2.099999999999999  acc: 0.89\n",
      "lambda: 2.109999999999999  acc: 0.89\n",
      "lambda: 2.1199999999999988  acc: 0.91\n",
      "lambda: 2.1299999999999986  acc: 0.91\n",
      "lambda: 2.1399999999999983  acc: 0.91\n",
      "lambda: 2.149999999999998  acc: 0.91\n",
      "lambda: 2.159999999999998  acc: 0.91\n",
      "lambda: 2.1699999999999977  acc: 0.91\n",
      "lambda: 2.1799999999999975  acc: 0.91\n",
      "lambda: 2.1899999999999973  acc: 0.91\n",
      "lambda: 2.199999999999997  acc: 0.91\n",
      "lambda: 2.209999999999997  acc: 0.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda: 2.2199999999999966  acc: 0.91\n",
      "lambda: 2.2299999999999964  acc: 0.91\n",
      "lambda: 2.239999999999996  acc: 0.91\n",
      "lambda: 2.249999999999996  acc: 0.9\n",
      "lambda: 2.259999999999996  acc: 0.9\n",
      "lambda: 2.2699999999999956  acc: 0.9\n",
      "lambda: 2.2799999999999954  acc: 0.9\n",
      "lambda: 2.289999999999995  acc: 0.91\n",
      "lambda: 2.299999999999995  acc: 0.91\n",
      "lambda: 2.3099999999999947  acc: 0.89\n",
      "lambda: 2.3199999999999945  acc: 0.91\n",
      "lambda: 2.3299999999999943  acc: 0.91\n",
      "lambda: 2.339999999999994  acc: 0.89\n",
      "lambda: 2.349999999999994  acc: 0.9\n",
      "lambda: 2.3599999999999937  acc: 0.91\n",
      "lambda: 2.3699999999999934  acc: 0.77\n",
      "lambda: 2.3799999999999932  acc: 0.77\n",
      "lambda: 2.389999999999993  acc: 0.79\n",
      "lambda: 2.399999999999993  acc: 0.78\n",
      "lambda: 2.4099999999999926  acc: 0.78\n",
      "lambda: 2.4199999999999924  acc: 0.58\n",
      "lambda: 2.429999999999992  acc: 0.59\n",
      "lambda: 2.439999999999992  acc: 0.59\n",
      "lambda: 2.4499999999999917  acc: 0.59\n",
      "lambda: 2.4599999999999915  acc: 0.56\n",
      "lambda: 2.4699999999999913  acc: 0.56\n",
      "lambda: 2.479999999999991  acc: 0.56\n",
      "lambda: 2.489999999999991  acc: 0.55\n",
      "lambda: 2.4999999999999907  acc: 0.55\n",
      "lambda: 2.5099999999999905  acc: 0.55\n",
      "lambda: 2.5199999999999902  acc: 0.55\n",
      "lambda: 2.52999999999999  acc: 0.55\n",
      "lambda: 2.53999999999999  acc: 0.55\n",
      "lambda: 2.5499999999999896  acc: 0.57\n",
      "lambda: 2.5599999999999894  acc: 0.57\n",
      "lambda: 2.569999999999989  acc: 0.57\n",
      "lambda: 2.579999999999989  acc: 0.57\n",
      "lambda: 2.5899999999999888  acc: 0.57\n",
      "lambda: 2.5999999999999885  acc: 0.56\n",
      "lambda: 2.6099999999999883  acc: 0.58\n",
      "lambda: 2.619999999999988  acc: 0.57\n",
      "lambda: 2.629999999999988  acc: 0.57\n",
      "lambda: 2.6399999999999877  acc: 0.58\n",
      "lambda: 2.6499999999999875  acc: 0.6\n",
      "lambda: 2.6599999999999873  acc: 0.6\n",
      "lambda: 2.669999999999987  acc: 0.6\n",
      "lambda: 2.679999999999987  acc: 0.59\n",
      "lambda: 2.6899999999999866  acc: 0.59\n",
      "lambda: 2.6999999999999864  acc: 0.59\n",
      "lambda: 2.709999999999986  acc: 0.58\n",
      "lambda: 2.719999999999986  acc: 0.58\n",
      "lambda: 2.7299999999999858  acc: 0.59\n",
      "lambda: 2.7399999999999856  acc: 0.59\n",
      "lambda: 2.7499999999999853  acc: 0.59\n",
      "lambda: 2.759999999999985  acc: 0.59\n",
      "lambda: 2.769999999999985  acc: 0.59\n",
      "lambda: 2.7799999999999847  acc: 0.59\n",
      "lambda: 2.7899999999999845  acc: 0.59\n",
      "lambda: 2.7999999999999843  acc: 0.59\n",
      "lambda: 2.809999999999984  acc: 0.59\n",
      "lambda: 2.819999999999984  acc: 0.59\n",
      "lambda: 2.8299999999999836  acc: 0.59\n",
      "lambda: 2.8399999999999834  acc: 0.59\n",
      "lambda: 2.849999999999983  acc: 0.59\n",
      "lambda: 2.859999999999983  acc: 0.59\n",
      "lambda: 2.869999999999983  acc: 0.58\n",
      "lambda: 2.8799999999999826  acc: 0.58\n",
      "lambda: 2.8899999999999824  acc: 0.58\n",
      "lambda: 2.899999999999982  acc: 0.58\n",
      "lambda: 2.909999999999982  acc: 0.58\n",
      "lambda: 2.9199999999999817  acc: 0.58\n",
      "lambda: 2.9299999999999815  acc: 0.58\n",
      "lambda: 2.9399999999999813  acc: 0.58\n",
      "lambda: 2.949999999999981  acc: 0.58\n",
      "lambda: 2.959999999999981  acc: 0.58\n",
      "lambda: 2.9699999999999807  acc: 0.58\n",
      "lambda: 2.9799999999999804  acc: 0.59\n",
      "lambda: 2.9899999999999802  acc: 0.58\n",
      "lambda: 2.99999999999998  acc: 0.58\n",
      "lambda: 3.00999999999998  acc: 0.58\n",
      "lambda: 3.0199999999999796  acc: 0.58\n",
      "lambda: 3.0299999999999794  acc: 0.58\n",
      "lambda: 3.039999999999979  acc: 0.58\n",
      "lambda: 3.049999999999979  acc: 0.58\n",
      "lambda: 3.0599999999999787  acc: 0.58\n",
      "lambda: 3.0699999999999785  acc: 0.58\n",
      "lambda: 3.0799999999999783  acc: 0.59\n",
      "lambda: 3.089999999999978  acc: 0.59\n",
      "lambda: 3.099999999999978  acc: 0.59\n",
      "lambda: 3.1099999999999777  acc: 0.59\n",
      "lambda: 3.1199999999999775  acc: 0.59\n",
      "lambda: 3.1299999999999772  acc: 0.59\n",
      "lambda: 3.139999999999977  acc: 0.59\n",
      "lambda: 3.149999999999977  acc: 0.59\n",
      "lambda: 3.1599999999999766  acc: 0.59\n",
      "lambda: 3.1699999999999764  acc: 0.59\n",
      "lambda: 3.179999999999976  acc: 0.6\n",
      "lambda: 3.189999999999976  acc: 0.6\n",
      "lambda: 3.1999999999999758  acc: 0.6\n",
      "lambda: 3.2099999999999755  acc: 0.6\n",
      "lambda: 3.2199999999999753  acc: 0.6\n",
      "lambda: 3.229999999999975  acc: 0.6\n",
      "lambda: 3.239999999999975  acc: 0.6\n",
      "lambda: 3.2499999999999747  acc: 0.6\n",
      "lambda: 3.2599999999999745  acc: 0.6\n",
      "lambda: 3.2699999999999743  acc: 0.6\n",
      "lambda: 3.279999999999974  acc: 0.6\n",
      "lambda: 3.289999999999974  acc: 0.6\n",
      "lambda: 3.2999999999999736  acc: 0.6\n",
      "lambda: 3.3099999999999734  acc: 0.6\n",
      "lambda: 3.319999999999973  acc: 0.6\n",
      "lambda: 3.329999999999973  acc: 0.6\n",
      "lambda: 3.3399999999999728  acc: 0.6\n",
      "lambda: 3.3499999999999726  acc: 0.6\n",
      "lambda: 3.3599999999999723  acc: 0.6\n",
      "lambda: 3.369999999999972  acc: 0.6\n",
      "lambda: 3.379999999999972  acc: 0.6\n",
      "lambda: 3.3899999999999717  acc: 0.6\n",
      "lambda: 3.3999999999999715  acc: 0.6\n",
      "lambda: 3.4099999999999713  acc: 0.61\n",
      "lambda: 3.419999999999971  acc: 0.61\n",
      "lambda: 3.429999999999971  acc: 0.61\n",
      "lambda: 3.4399999999999706  acc: 0.61\n",
      "lambda: 3.4499999999999704  acc: 0.61\n",
      "lambda: 3.45999999999997  acc: 0.61\n",
      "lambda: 3.46999999999997  acc: 0.61\n",
      "lambda: 3.47999999999997  acc: 0.61\n",
      "lambda: 3.4899999999999696  acc: 0.61\n",
      "lambda: 3.4999999999999694  acc: 0.61\n",
      "lambda: 3.509999999999969  acc: 0.61\n",
      "lambda: 3.519999999999969  acc: 0.61\n",
      "lambda: 3.5299999999999687  acc: 0.61\n",
      "lambda: 3.5399999999999685  acc: 0.61\n",
      "lambda: 3.5499999999999683  acc: 0.61\n",
      "lambda: 3.559999999999968  acc: 0.61\n",
      "lambda: 3.569999999999968  acc: 0.61\n",
      "lambda: 3.5799999999999677  acc: 0.61\n",
      "lambda: 3.5899999999999674  acc: 0.61\n",
      "lambda: 3.5999999999999672  acc: 0.61\n",
      "lambda: 3.609999999999967  acc: 0.61\n",
      "lambda: 3.619999999999967  acc: 0.61\n",
      "lambda: 3.6299999999999666  acc: 0.61\n",
      "lambda: 3.6399999999999664  acc: 0.61\n",
      "lambda: 3.649999999999966  acc: 0.61\n",
      "lambda: 3.659999999999966  acc: 0.61\n",
      "lambda: 3.6699999999999657  acc: 0.61\n",
      "lambda: 3.6799999999999655  acc: 0.61\n",
      "lambda: 3.6899999999999653  acc: 0.61\n",
      "lambda: 3.699999999999965  acc: 0.61\n",
      "lambda: 3.709999999999965  acc: 0.61\n",
      "lambda: 3.7199999999999647  acc: 0.61\n",
      "lambda: 3.7299999999999645  acc: 0.61\n",
      "lambda: 3.7399999999999642  acc: 0.61\n",
      "lambda: 3.749999999999964  acc: 0.61\n",
      "lambda: 3.759999999999964  acc: 0.61\n",
      "lambda: 3.7699999999999636  acc: 0.61\n",
      "lambda: 3.7799999999999634  acc: 0.61\n",
      "lambda: 3.789999999999963  acc: 0.61\n",
      "lambda: 3.799999999999963  acc: 0.61\n",
      "lambda: 3.8099999999999627  acc: 0.61\n",
      "lambda: 3.8199999999999625  acc: 0.61\n",
      "lambda: 3.8299999999999623  acc: 0.61\n",
      "lambda: 3.839999999999962  acc: 0.61\n",
      "lambda: 3.849999999999962  acc: 0.6\n",
      "lambda: 3.8599999999999617  acc: 0.6\n",
      "lambda: 3.8699999999999615  acc: 0.6\n",
      "lambda: 3.8799999999999613  acc: 0.6\n",
      "lambda: 3.889999999999961  acc: 0.6\n",
      "lambda: 3.899999999999961  acc: 0.61\n",
      "lambda: 3.9099999999999606  acc: 0.61\n",
      "lambda: 3.9199999999999604  acc: 0.61\n",
      "lambda: 3.92999999999996  acc: 0.61\n",
      "lambda: 3.93999999999996  acc: 0.61\n",
      "lambda: 3.9499999999999598  acc: 0.61\n",
      "lambda: 3.9599999999999596  acc: 0.61\n",
      "lambda: 3.9699999999999593  acc: 0.61\n",
      "lambda: 3.979999999999959  acc: 0.61\n",
      "lambda: 3.989999999999959  acc: 0.61\n",
      "lambda: 3.9999999999999587  acc: 0.61\n",
      "lambda: 4.009999999999959  acc: 0.61\n",
      "lambda: 4.019999999999959  acc: 0.61\n",
      "lambda: 4.0299999999999585  acc: 0.61\n",
      "lambda: 4.039999999999958  acc: 0.61\n",
      "lambda: 4.049999999999958  acc: 0.61\n",
      "lambda: 4.059999999999958  acc: 0.61\n",
      "lambda: 4.069999999999958  acc: 0.61\n",
      "lambda: 4.079999999999957  acc: 0.61\n",
      "lambda: 4.089999999999957  acc: 0.61\n",
      "lambda: 4.099999999999957  acc: 0.61\n",
      "lambda: 4.109999999999957  acc: 0.61\n",
      "lambda: 4.119999999999957  acc: 0.61\n",
      "lambda: 4.129999999999956  acc: 0.61\n",
      "lambda: 4.139999999999956  acc: 0.61\n",
      "lambda: 4.149999999999956  acc: 0.61\n",
      "lambda: 4.159999999999956  acc: 0.61\n",
      "lambda: 4.1699999999999555  acc: 0.61\n",
      "lambda: 4.179999999999955  acc: 0.61\n",
      "lambda: 4.189999999999955  acc: 0.61\n",
      "lambda: 4.199999999999955  acc: 0.61\n",
      "lambda: 4.209999999999955  acc: 0.61\n",
      "lambda: 4.2199999999999545  acc: 0.61\n",
      "lambda: 4.229999999999954  acc: 0.61\n",
      "lambda: 4.239999999999954  acc: 0.61\n",
      "lambda: 4.249999999999954  acc: 0.61\n",
      "lambda: 4.259999999999954  acc: 0.6\n",
      "lambda: 4.269999999999953  acc: 0.6\n",
      "lambda: 4.279999999999953  acc: 0.6\n",
      "lambda: 4.289999999999953  acc: 0.6\n",
      "lambda: 4.299999999999953  acc: 0.6\n",
      "lambda: 4.3099999999999525  acc: 0.6\n",
      "lambda: 4.319999999999952  acc: 0.6\n",
      "lambda: 4.329999999999952  acc: 0.6\n",
      "lambda: 4.339999999999952  acc: 0.6\n",
      "lambda: 4.349999999999952  acc: 0.6\n",
      "lambda: 4.3599999999999515  acc: 0.6\n",
      "lambda: 4.369999999999951  acc: 0.6\n",
      "lambda: 4.379999999999951  acc: 0.6\n",
      "lambda: 4.389999999999951  acc: 0.6\n",
      "lambda: 4.399999999999951  acc: 0.6\n",
      "lambda: 4.40999999999995  acc: 0.6\n",
      "lambda: 4.41999999999995  acc: 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda: 4.42999999999995  acc: 0.6\n",
      "lambda: 4.43999999999995  acc: 0.6\n",
      "lambda: 4.4499999999999496  acc: 0.6\n",
      "lambda: 4.459999999999949  acc: 0.6\n",
      "lambda: 4.469999999999949  acc: 0.6\n",
      "lambda: 4.479999999999949  acc: 0.6\n",
      "lambda: 4.489999999999949  acc: 0.6\n",
      "lambda: 4.4999999999999485  acc: 0.6\n",
      "lambda: 4.509999999999948  acc: 0.6\n",
      "lambda: 4.519999999999948  acc: 0.61\n",
      "lambda: 4.529999999999948  acc: 0.61\n",
      "lambda: 4.539999999999948  acc: 0.61\n",
      "lambda: 4.549999999999947  acc: 0.61\n",
      "lambda: 4.559999999999947  acc: 0.61\n",
      "lambda: 4.569999999999947  acc: 0.61\n",
      "lambda: 4.579999999999947  acc: 0.61\n",
      "lambda: 4.589999999999947  acc: 0.61\n",
      "lambda: 4.599999999999946  acc: 0.61\n",
      "lambda: 4.609999999999946  acc: 0.61\n",
      "lambda: 4.619999999999946  acc: 0.61\n",
      "lambda: 4.629999999999946  acc: 0.61\n",
      "lambda: 4.6399999999999455  acc: 0.61\n",
      "lambda: 4.649999999999945  acc: 0.61\n",
      "lambda: 4.659999999999945  acc: 0.61\n",
      "lambda: 4.669999999999945  acc: 0.6\n",
      "lambda: 4.679999999999945  acc: 0.6\n",
      "lambda: 4.689999999999944  acc: 0.6\n",
      "lambda: 4.699999999999944  acc: 0.61\n",
      "lambda: 4.709999999999944  acc: 0.61\n",
      "lambda: 4.719999999999944  acc: 0.61\n",
      "lambda: 4.729999999999944  acc: 0.61\n",
      "lambda: 4.739999999999943  acc: 0.61\n",
      "lambda: 4.749999999999943  acc: 0.61\n",
      "lambda: 4.759999999999943  acc: 0.61\n",
      "lambda: 4.769999999999943  acc: 0.63\n",
      "lambda: 4.7799999999999425  acc: 0.62\n",
      "lambda: 4.789999999999942  acc: 0.62\n",
      "lambda: 4.799999999999942  acc: 0.62\n",
      "lambda: 4.809999999999942  acc: 0.62\n",
      "lambda: 4.819999999999942  acc: 0.62\n",
      "lambda: 4.8299999999999415  acc: 0.62\n",
      "lambda: 4.839999999999941  acc: 0.62\n",
      "lambda: 4.849999999999941  acc: 0.62\n",
      "lambda: 4.859999999999941  acc: 0.62\n",
      "lambda: 4.869999999999941  acc: 0.62\n",
      "lambda: 4.87999999999994  acc: 0.62\n",
      "lambda: 4.88999999999994  acc: 0.62\n",
      "lambda: 4.89999999999994  acc: 0.62\n",
      "lambda: 4.90999999999994  acc: 0.62\n",
      "lambda: 4.9199999999999395  acc: 0.62\n",
      "lambda: 4.929999999999939  acc: 0.62\n",
      "lambda: 4.939999999999939  acc: 0.62\n",
      "lambda: 4.949999999999939  acc: 0.62\n",
      "lambda: 4.959999999999939  acc: 0.62\n",
      "lambda: 4.9699999999999385  acc: 0.62\n",
      "lambda: 4.979999999999938  acc: 0.63\n",
      "lambda: 4.989999999999938  acc: 0.63\n",
      "lambda: 4.999999999999938  acc: 0.63\n"
     ]
    }
   ],
   "source": [
    "# record expert actions2\n",
    "reward2 = [[0 for _ in range(10)] for _ in range(10)]\n",
    "reward2[1][4:7] = [-100 for _ in range(3)]\n",
    "reward2[2][4] = -100\n",
    "reward2[2][6] = -100\n",
    "reward2[3][4] = -100\n",
    "reward2[3][6:9] = [-100 for _ in range(3)]\n",
    "reward2[4][4] = -100\n",
    "reward2[4][8] = -100\n",
    "reward2[5][4] = -100\n",
    "reward2[5][8] = -100\n",
    "reward2[6][4] = -100\n",
    "reward2[6][8] = -100\n",
    "reward2[7][6:9] = [-100 for _ in range(3)]\n",
    "reward2[8][6] = -100\n",
    "reward2[9][9] = 10\n",
    "reward_2 = []\n",
    "reward2 = np.array(reward2).transpose()\n",
    "for lines in reward2:\n",
    "    reward_2 += list(lines)\n",
    "\n",
    "exp_action2 = [0 for _ in range(100)]\n",
    "values = optimal_state_val(values, w, gamma, reward_2, thres)\n",
    "for state in range(100):\n",
    "    exp_action2[state] = np.argmax([compute(state, 0, w, gamma, reward_2, values),\n",
    "                                   compute(state, 1, w, gamma, reward_2, values),\n",
    "                                   compute(state, 2, w, gamma, reward_2, values),\n",
    "                                   compute(state, 3, w, gamma, reward_2, values)])\n",
    "\n",
    "lam_list2, acc_list2 = sweep(exp_action2, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index2 = np.argmax(acc_list2)\n",
    "lam_max2 = lam_list2[max_index2]\n",
    "c_opt2, D_opt2, b_opt2 = get_c_D_b(exp_action2, P_acts, lam_max2, 100)\n",
    "reward_opt2 = np.array(get_reward(c_opt2, D_opt2, b_opt2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal policy for extracted reward function 2:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1147a5ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare - Optimal policy for extracted reward function 2:\n",
      "Compare - Optimal policy for ground truth reward function 2:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1147b1a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x128fe18d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Q25_1\n",
    "values = optimal_state_val(values, w, gamma, reward_opt2, 0.00001)\n",
    "pis = [0 for _ in range(100)]\n",
    "arrows = ['\\u2190', '\\u2191', '\\u2192', '\\u2193']\n",
    "for state in range(100):\n",
    "    pis[state] = arrows[np.argmax([compute(state, 0, w, gamma, reward_opt2, values),\n",
    "                                   compute(state, 1, w, gamma, reward_opt2, values),\n",
    "                                   compute(state, 2, w, gamma, reward_opt2, values),\n",
    "                                   compute(state, 3, w, gamma, reward_opt2, values)])]\n",
    "\n",
    "\n",
    "\n",
    "reward2 = [[0 for _ in range(10)] for _ in range(10)]\n",
    "reward2[1][4:7] = [-100 for _ in range(3)]\n",
    "reward2[2][4] = -100\n",
    "reward2[2][6] = -100\n",
    "reward2[3][4] = -100\n",
    "reward2[3][6:9] = [-100 for _ in range(3)]\n",
    "reward2[4][4] = -100\n",
    "reward2[4][8] = -100\n",
    "reward2[5][4] = -100\n",
    "reward2[5][8] = -100\n",
    "reward2[6][4] = -100\n",
    "reward2[6][8] = -100\n",
    "reward2[7][6:9] = [-100 for _ in range(3)]\n",
    "reward2[8][6] = -100\n",
    "reward2[9][9] = 10\n",
    "reward_2 = []\n",
    "reward2 = np.array(reward2).transpose()\n",
    "for lines in reward2:\n",
    "    reward_2 += list(lines)\n",
    "\n",
    "values = optimal_state_val(values, w, gamma, reward_2, thres)\n",
    "\n",
    "pis2 = [0 for _ in range(100)]\n",
    "arrows = ['\\u2190', '\\u2191', '\\u2192', '\\u2193']\n",
    "for state in range(100):\n",
    "    pis2[state] = arrows[np.argmax([compute(state, 0, w, gamma, reward_2, values),\n",
    "                                   compute(state, 1, w, gamma, reward_2, values),\n",
    "                                   compute(state, 2, w, gamma, reward_2, values),\n",
    "                                   compute(state, 3, w, gamma, reward_2, values)])]\n",
    "pis1_modified = []\n",
    "pis2_modified = []\n",
    "\n",
    "def convert(p):\n",
    "    if p == '\\u2190':\n",
    "        return '\\u21C7'\n",
    "    elif p == '\\u2191':\n",
    "        return '\\u21C8'\n",
    "    elif p == '\\u2192':\n",
    "        return '\\u21C9'\n",
    "    else:\n",
    "        return '\\u21CA'\n",
    "for p1, p2 in zip(pis, pis2):\n",
    "    if p1 != p2:\n",
    "        pis1_modified.append(convert(p1))\n",
    "        pis2_modified.append(convert(p2))\n",
    "    else:\n",
    "        pis1_modified.append(p1)\n",
    "        pis2_modified.append(p2)\n",
    "        \n",
    "pi0 = np.array(pis).reshape(10, 10).transpose()\n",
    "pi1 = np.array(pis1_modified).reshape(10, 10).transpose()\n",
    "pi2 = np.array(pis2_modified).reshape(10, 10).transpose()\n",
    "\n",
    "# optimal policy for extracted reward function 2\n",
    "print(\"Optimal policy for extracted reward function 2:\")\n",
    "plt.figure()\n",
    "tb = plt.table(cellText=pi0, loc=(0,0), cellLoc='center')\n",
    "tc = tb.properties()['child_artists']\n",
    "plt.title(\"Optimal policy for extracted reward function 2:\")\n",
    "for cell in tc:\n",
    "    cell.set_height(0.1)\n",
    "    cell.set_width(0.1)\n",
    "ax = plt.gca()\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.show()\n",
    "\n",
    "# compare extracted & ground truth\n",
    "print(\"Compare - Optimal policy for extracted reward function 2:\")\n",
    "plt.figure()\n",
    "tb = plt.table(cellText=pi1, loc=(0,0), cellLoc='center')\n",
    "tc = tb.properties()['child_artists']\n",
    "plt.title(\"Optimal policy for extracted reward function 2:\")\n",
    "for cell in tc:\n",
    "    cell.set_height(0.1)\n",
    "    cell.set_width(0.1)\n",
    "ax = plt.gca()\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "print(\"Compare - Optimal policy for ground truth reward function 2:\")\n",
    "plt.figure()\n",
    "tb2 = plt.table(cellText=pi2, loc=(0,0), cellLoc='center')\n",
    "tc2 = tb2.properties()['child_artists']\n",
    "plt.title(\"Optimal policy for ground truth reward function 2:\")\n",
    "for cell in tc2:\n",
    "    cell.set_height(0.1)\n",
    "    cell.set_width(0.1)\n",
    "    \n",
    "ax = plt.gca()\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
